{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests_html import HTMLSession\n",
    "from lxml import html \n",
    "from datetime import date,datetime\n",
    "import smtplib, ssl\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "import sys\n",
    "import re \n",
    "from bs4 import BeautifulSoup\n",
    "import nums_from_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetchSession(url):\n",
    "    session = HTMLSession()\n",
    "    r = session.get(url)\n",
    "    return r\n",
    "\n",
    "def getTrades(r):\n",
    "    table = r.html.find('table')[0]\n",
    "    rows = table.find('tr')\n",
    "    return rows[1:]\n",
    "\n",
    "def value_to_ints(value):\n",
    "    bad_chars = [\n",
    "        ',','$','-'\n",
    "    ]\n",
    "    for c in bad_chars:\n",
    "        value = value.replace(c,'')\n",
    "    low, high = [\n",
    "        int(x) for x in (value.split('  ', 1))\n",
    "    ]\n",
    "    return [low,high]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHTML(url):\n",
    "    r = fetchSession(url)\n",
    "    h = r.text\n",
    "    doc = BeautifulSoup(h, 'html.parser')\n",
    "    return doc\n",
    "\n",
    "def getTicker(trade_):\n",
    "    try:\n",
    "        return re.findall('\\[(.*?)\\]', trade_)[0]\n",
    "    except IndexError:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFirstRowEntry(ticker):\n",
    "    url = 'https://finance.yahoo.com/quote/{}/'.format(ticker)\n",
    "    soup = getHTML(url)\n",
    "    quote_summary = soup.find(id='quote-summary')\n",
    "    if quote_summary is None:\n",
    "        return ''\n",
    "    tables = quote_summary.find_all('table')\n",
    "    if len(tables) == 0:\n",
    "        return ''\n",
    "    # right side table\n",
    "    mc_table = tables[1]\n",
    "    # get all rows\n",
    "    mc_rows = mc_table.find_all('td')\n",
    "    # entire row \n",
    "    mc_string = str(mc_rows[1])\n",
    "    return mc_string\n",
    "\n",
    "def isStock(row_one):\n",
    "    flag = 'data-test=\"(.*)-value'\n",
    "    seach = re.search(\n",
    "        flag, row_one\n",
    "    )\n",
    "    if seach is None:\n",
    "        return -1\n",
    "    marker = seach.group(1)\n",
    "    if marker == 'MARKET_CAP':\n",
    "        return 1\n",
    "    elif marker == 'NET_ASSETS':\n",
    "        return 0\n",
    "    # N/A\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "def parseToMillions(value_string):\n",
    "    unit = value_string[-1:]\n",
    "    number = nums_from_string.get_nums(value_string)[0]\n",
    "    #keep in units of millions\n",
    "    if unit == 'B':\n",
    "        number = number * 1000\n",
    "    elif unit == 'T':\n",
    "        number = number * 1000000\n",
    "    return number\n",
    "\n",
    "def getNAVCAP(row_one):\n",
    "    value = re.search('>(.*)<', row_one).group(1)\n",
    "    if value == 'N/A':\n",
    "        return -1\n",
    "    return round(parseToMillions(value),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeToFile(trades):\n",
    "    with open('data/daily_trades.txt', 'w') as f:\n",
    "        for t in trades:\n",
    "            for (key,item) in t.items():\n",
    "                if key == 'Yahoo!':\n",
    "                    f.write(\n",
    "                        '%s\\n' % (\n",
    "                        item\n",
    "                        )\n",
    "                    )\n",
    "                else:\n",
    "                    f.write(\n",
    "                        '%s : %s\\n' % (\n",
    "                        key,item\n",
    "                        )\n",
    "                    )\n",
    "            f.write('\\n')\n",
    "\n",
    "def sendEmail(toList = False):\n",
    "    port = 465\n",
    "    send_email = 'ders.mailbot@gmail.com'\n",
    "    with open('data/password.txt','r') as f:\n",
    "        password = f.read()\n",
    "\n",
    "    with open('data/daily_trades.txt', 'r') as f:\n",
    "        data = f.read()\n",
    "    \n",
    "    # get list of emails from text file in data folder \n",
    "    recipients = []\n",
    "    if toList:\n",
    "        with open('data/mailing_list.txt','r') as f:\n",
    "            lines = f.readlines()\n",
    "        for l in lines:\n",
    "            recipients.append(l.strip())\n",
    "    else:\n",
    "        recipients = [send_email]\n",
    "    # if the length of the string from the file is not 0, then there was a \n",
    "    # (major) trade executed today\n",
    "    if len(data) != 0:\n",
    "        print('major trade found.')\n",
    "        message = MIMEMultipart('alternative')\n",
    "        message['Subject'] = 'Trade Alert'\n",
    "        message['From'] = send_email\n",
    "        message['To'] = ', '.join(recipients) # change post testing\n",
    "        message['Bcc'] = ''\n",
    "        body = MIMEText(data, 'plain')\n",
    "        message.attach(body)\n",
    "\n",
    "        context = ssl.create_default_context()\n",
    "        with smtplib.SMTP_SSL('smtp.gmail.com', port, context=context) as server:\n",
    "            server.login(send_email, password)\n",
    "            server.sendmail(\n",
    "                send_email, recipients, message.as_string()\n",
    "            )\n",
    "            print('mail sent.')\n",
    "    else:\n",
    "        print('no major trades.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanNewsURLQuery(trade):\n",
    "    return (\n",
    "        'https://news.google.com/search?q={}&hl=en-US&gl=US&ceid=US%3Aen'.format(\n",
    "            trade.replace(' ', '%20').replace(',', '').replace('[','%5B').replace(']','%5D')\n",
    "            )\n",
    "        )\n",
    "\n",
    "def getArticleTextFromUrl(url):\n",
    "    soup = getHTML(url)\n",
    "    articles = soup.find_all('article')\n",
    "    return str(articles)\n",
    "\n",
    "def findNOccurrence(str, sub, n):\n",
    "    val = -1\n",
    "    for i in range(0,n):\n",
    "        val = str.find(sub, val + 1)\n",
    "    return val\n",
    "\n",
    "def getNewsUrlsTitles(full_article_string):\n",
    "    list_of_urls_titles = []\n",
    "    list_of_articles = full_article_string.split('</article>')\n",
    "    i = 0\n",
    "    for a in list_of_articles[:-1]:\n",
    "        if i > 2:\n",
    "            break\n",
    "        start_ind = findNOccurrence(\n",
    "            a, 'href', 2\n",
    "        )\n",
    "        slice = a[start_ind:]\n",
    "        url = slice[slice.find('articles'):slice.find('\">')]\n",
    "        title = slice[slice.find('>'):slice.find('<')][1:]\n",
    "        list_of_urls_titles.append(\n",
    "            {\n",
    "                'title':title,\n",
    "                'url':'news.google.com/{}'.format(url)\n",
    "            }\n",
    "        )\n",
    "        i += 1\n",
    "    return list_of_urls_titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method to scrape trades with mkt cap and purchase logic all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrapeImportantTrades(today=datetime.today().date(), onlyToday=False):\n",
    "    r = fetchSession('https://sec.report/Senate-Stock-Disclosures')\n",
    "    # if website is down\n",
    "    try:\n",
    "        trades = getTrades(r)\n",
    "    except IndexError:\n",
    "        print('website may be down. quitting.')\n",
    "        sys.exit(1)\n",
    "\n",
    "    n = len(trades)\n",
    "    all_trades = []\n",
    "\n",
    "    for i in range(0,n,2):\n",
    "        imp_trade = False\n",
    "        l1_elements = trades[i].find('td')\n",
    "        l2_elements = trades[i+1].find('td')[:-1]\n",
    "\n",
    "        # make sure trade happened today before doing anything \n",
    "        file_date, trade_date = l1_elements[0].text.split('\\n')\n",
    "        if file_date != today and onlyToday:\n",
    "            break\n",
    "\n",
    "        # ensure trade is a purchase, otherwise contniue to next trade\n",
    "        trade_type = l2_elements[0].text.split('\\n', 1)[0]\n",
    "        if trade_type != 'Purchase':\n",
    "            continue\n",
    "\n",
    "        trade = l1_elements[1].text\n",
    "        senator = l1_elements[2].text\n",
    "        value = value_to_ints(l2_elements[1].text)\n",
    "        \n",
    "        ticker = getTicker(trade)\n",
    "        # move on if ticker is invalid\n",
    "        if ticker == '':\n",
    "            continue\n",
    "\n",
    "        row_one = getFirstRowEntry(ticker)\n",
    "        mkt_cap = getNAVCAP(row_one)\n",
    "        small_mktCap = mkt_cap < 2000 and mkt_cap > 0\n",
    "        medium_mktCap = mkt_cap >= 2000 and mkt_cap <= 10000\n",
    "        large_mktCap = mkt_cap > 10000\n",
    "        # any small caps, medium purchase medium caps, large purchase large cap\n",
    "        if isStock(row_one) and small_mktCap:\n",
    "            imp_trade = True\n",
    "            cap_string = 'small'\n",
    "        elif isStock(row_one) and medium_mktCap and value[0] >= 50000:\n",
    "            imp_trade = True\n",
    "            cap_string = 'medium'\n",
    "        elif isStock(row_one) and large_mktCap and value[0] >= 100000:\n",
    "            imp_trade = True\n",
    "            cap_string = 'large'\n",
    "\n",
    "        if imp_trade:\n",
    "            url = 'https://finance.yahoo.com/quote/{}/'.format(ticker)\n",
    "            trade_dict = {\n",
    "                'trade date' : trade_date,\n",
    "                'file date' : file_date,\n",
    "                'senator' : senator,\n",
    "                'trade' : trade,\n",
    "                'trade type' : trade_type,\n",
    "                'value' : value,\n",
    "                'mkt cap' : cap_string,\n",
    "                'yahoo finance' : url,\n",
    "            }\n",
    "            all_trades.append(trade_dict)\n",
    "    return all_trades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_trades_all = scrapeImportantTrades()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no important trades today.\n"
     ]
    }
   ],
   "source": [
    "important_trades_today = scrapeImportantTrades(onlyToday=True)\n",
    "if len(important_trades_today) != 0:\n",
    "    print(important_trades_today)\n",
    "else:\n",
    "    print('no important trades today.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Email Appearance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanText(trades_list):\n",
    "    trades_for_txt = []\n",
    "    for t in trades_list:\n",
    "        trade_date = str(t['trade date']) + ' (' + str((\n",
    "                datetime.today().date() - datetime.strptime(\n",
    "                    t['trade date'], '%Y-%m-%d'\n",
    "                ).date()\n",
    "            )).split(',')[0] + ' ago)'\n",
    "\n",
    "        value_string = '$' + (\n",
    "            \"{:,}\".format(t['value'][0])\n",
    "        ) + ' to $' + (\n",
    "            \"{:,}\".format(t['value'][1])\n",
    "        )\n",
    "\n",
    "        if t['mkt cap'] == 'small':\n",
    "            mkt_cap_string = 'Small Cap (Under $2B)'\n",
    "        elif t['mkt cap'] == 'medium':\n",
    "            mkt_cap_string = 'Medium Cap ($2B to $10B)'\n",
    "        else:\n",
    "            mkt_cap_string = 'Large Cap (Over $10B)'\n",
    "\n",
    "        list_of_titles_urls = getNewsUrlsTitles(\n",
    "            getArticleTextFromUrl(\n",
    "                cleanNewsURLQuery(\n",
    "                    t['trade']\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        # debug weird behavior for third ECOM trade\n",
    "        # first two print the same thing fine, last one prints empty url and title\n",
    "        # print(getTicker(t['trade']))\n",
    "        # for i in list_of_titles_urls:\n",
    "        #     for key,value in i.items():\n",
    "        #         print(key, ':', value)\n",
    "        if len(list_of_titles_urls) > 1:\n",
    "            trades_for_txt.append(\n",
    "                {\n",
    "                    'Trade Date' : trade_date,\n",
    "                    'File Date' : t['file date'],\n",
    "                    'Senator' : t['senator'],\n",
    "                    'Equity' : t['trade'],\n",
    "                    'Trade Value' : value_string,\n",
    "                    'Market Cap' : mkt_cap_string,\n",
    "                    'Yahoo!' : t['yahoo finance'],\n",
    "                    list_of_titles_urls[0]['title'] : list_of_titles_urls[0]['url'],\n",
    "                    list_of_titles_urls[1]['title'] : list_of_titles_urls[1]['url'],\n",
    "                    list_of_titles_urls[2]['title'] : list_of_titles_urls[2]['url']\n",
    "                }\n",
    "            )\n",
    "        else:\n",
    "            trades_for_txt.append(\n",
    "                {\n",
    "                    'Trade Date' : trade_date,\n",
    "                    'File Date' : t['file date'],\n",
    "                    'Senator' : t['senator'],\n",
    "                    'Equity' : t['trade'],\n",
    "                    'Trade Value' : value_string,\n",
    "                    'Market Cap' : mkt_cap_string,\n",
    "                    'Yahoo!' : t['yahoo finance']\n",
    "                }\n",
    "            )\n",
    "    return trades_for_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trade Date : 2022-03-30 (26 days ago)\n",
      "File Date : 2022-04-08\n",
      "Senator : Thomas H Tuberville [Tuberville, Tommy]\n",
      "Equity : Limestone Bancorp, Inc. - Common Stock [LMST]\n",
      "Trade Value : $1,001 to $15,000\n",
      "Market Cap : Small Cap (Under $2B)\n",
      "https://finance.yahoo.com/quote/LMST/\n",
      "Limestone Bancorp : Reports Net Income of $3.6 million, or $0.47 per Diluted Share, for the 1st Quarter of 2022 - Form 8-K : news.google.com/articles/CBMitwFodHRwczovL3d3dy5tYXJrZXRzY3JlZW5lci5jb20vcXVvdGUvc3RvY2svTElNRVNUT05FLUJBTkNPUlAtSU5DLTQ0MzE1ODQ2L25ld3MvTGltZXN0b25lLUJhbmNvcnAtUmVwb3J0cy1OZXQtSW5jb21lLW9mLTMtNi1taWxsaW9uLW9yLTAtNDctcGVyLURpbHV0ZWQtU2hhcmUtZm9yLXRoZS0xc3QtUXVhci00MDEwMjUwNy_SAbsBaHR0cHM6Ly93d3cubWFya2V0c2NyZWVuZXIuY29tL2FtcC9xdW90ZS9zdG9jay9MSU1FU1RPTkUtQkFOQ09SUC1JTkMtNDQzMTU4NDYvbmV3cy9MaW1lc3RvbmUtQmFuY29ycC1SZXBvcnRzLU5ldC1JbmNvbWUtb2YtMy02LW1pbGxpb24tb3ItMC00Ny1wZXItRGlsdXRlZC1TaGFyZS1mb3ItdGhlLTFzdC1RdWFyLTQwMTAyNTA3Lw?hl=en-US&amp;gl=US&amp;ceid=US%3Aen\n",
      "Limestone Bancorp, Inc. Declares First Quarter Cash Dividend of $0.05 Per Common Share : news.google.com/articles/CBMijQFodHRwczovL3d3dy5idXNpbmVzc3dpcmUuY29tL25ld3MvaG9tZS8yMDIyMDIyMzAwNjI1MS9lbi9MaW1lc3RvbmUtQmFuY29ycC1JbmMuLURlY2xhcmVzLUZpcnN0LVF1YXJ0ZXItQ2FzaC1EaXZpZGVuZC1vZi0wLjA1LVBlci1Db21tb24tU2hhcmXSAQA?hl=en-US&amp;gl=US&amp;ceid=US%3Aen\n",
      "Zacks.com featured highlights include: BancFirst Corp., Fulton Financial Corp., Limestone Bancorp, Inc. and Cowen Inc. : news.google.com/articles/CBMiVWh0dHBzOi8vZmluYW5jZS55YWhvby5jb20vbmV3cy96YWNrcy1jb20tZmVhdHVyZWQtaGlnaGxpZ2h0cy1iYW5jZmlyc3QtMTI0MDEyNjUyLmh0bWzSAV1odHRwczovL2ZpbmFuY2UueWFob28uY29tL2FtcGh0bWwvbmV3cy96YWNrcy1jb20tZmVhdHVyZWQtaGlnaGxpZ2h0cy1iYW5jZmlyc3QtMTI0MDEyNjUyLmh0bWw?hl=en-US&amp;gl=US&amp;ceid=US%3Aen\n"
     ]
    }
   ],
   "source": [
    "cleaned_trades = cleanText(important_trades_all)\n",
    "for key,value in cleaned_trades[0].items():\n",
    "    if key == 'Yahoo!':\n",
    "        print(value)\n",
    "        continue\n",
    "    print(key, ':', value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "writeToFile(cleaned_trades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "major trade found.\n",
      "mail sent.\n"
     ]
    }
   ],
   "source": [
    "sendEmail(toList = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Links to Google News Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes trade line and converts to url formatting\n",
    "def cleanNewsURLQuery(trade):\n",
    "    return (\n",
    "        'https://news.google.com/search?q={}&hl=en-US&gl=US&ceid=US%3Aen'.format(\n",
    "            trade.replace(' ', '%20').replace(',', '').replace('[','%5B').replace(']','%5D')\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getArticleTextFromUrl(url):\n",
    "    soup = getHTML(url)\n",
    "    articles = soup.find_all('article')\n",
    "    return str(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findNOccurrence(str, sub, n):\n",
    "    val = -1\n",
    "    for i in range(0,n):\n",
    "        val = str.find(sub, val + 1)\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get urls of first 3 news stories \n",
    "def getNewsUrlsTitles(full_article_string):\n",
    "    list_of_urls_titles = []\n",
    "    list_of_articles = full_article_string.split('</article>')\n",
    "    i = 0\n",
    "    for a in list_of_articles:\n",
    "        if i > 2:\n",
    "            break\n",
    "        start_ind = findNOccurrence(\n",
    "            a, 'href', 2\n",
    "        )\n",
    "        slice = a[start_ind:]\n",
    "        url = slice[slice.find('articles'):slice.find('\">')]\n",
    "        title = slice[slice.find('>'):slice.find('<')][1:]\n",
    "        list_of_urls_titles.append(\n",
    "            {\n",
    "                'title':title,\n",
    "                'url':'news.google.com/{}'.format(url)\n",
    "            }\n",
    "        )\n",
    "        i += 1\n",
    "    return list_of_urls_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_articles = []\n",
    "for t in important_trades_all:\n",
    "    url = cleanNewsURLQuery(t['trade'])\n",
    "    all_articles.append(\n",
    "        getNewsUrlsTitles(getArticleTextFromUrl(url))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Limestone Bancorp Reports Net Income of $3.6 million, or $0.47 per Diluted Share, for the 1st Quarter of 2022'"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_articles[0][0]['title']"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "953dcbbcda697a7411822c4a3e6fce342850cb4e21d1ef3e2d71fa3ba11fc2f4"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
